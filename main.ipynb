{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mpld3\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mpld3) (3.1.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mpld3) (3.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->mpld3) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mpld3) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mpld3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mpld3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->mpld3) (1.16.0)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "   ---------------------------------------- 0.0/202.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/202.6 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 30.7/202.6 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 30.7/202.6 kB ? eta -:--:--\n",
      "   ------------- ------------------------- 71.7/202.6 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 71.7/202.6 kB 653.6 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 112.6/202.6 kB 504.4 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 112.6/202.6 kB 504.4 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 112.6/202.6 kB 504.4 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 112.6/202.6 kB 504.4 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 143.4/202.6 kB 327.1 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 143.4/202.6 kB 327.1 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 153.6/202.6 kB 277.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 153.6/202.6 kB 277.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 153.6/202.6 kB 277.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 153.6/202.6 kB 277.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 153.6/202.6 kB 277.8 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 174.1/202.6 kB 227.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 174.1/202.6 kB 227.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 174.1/202.6 kB 227.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 174.1/202.6 kB 227.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/202.6 kB 199.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 202.6/202.6 kB 201.8 kB/s eta 0:00:00\n",
      "Installing collected packages: mpld3\n",
      "Successfully installed mpld3-0.5.10\n",
      "Collecting git+https://github.com/javadba/mpld3@display_fix\n",
      "  Cloning https://github.com/javadba/mpld3 (to revision display_fix) to c:\\users\\hp\\appdata\\local\\temp\\pip-req-build-g3hoh_ep\n",
      "  Resolved https://github.com/javadba/mpld3 to commit 57ed37dbc4749259b1b46cba8bf28de802972adb\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: mpld3\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n",
      "  Created wheel for mpld3: filename=mpld3-0.3.1.dev1-py3-none-any.whl size=117399 sha256=1876f48f10dea339e449c4a5ae4d0e1d34a96178a15f110ab7c79d90dcb48be0\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-8j7a9cjg\\wheels\\9d\\96\\b0\\a96bed79e2bc1d3e74d0ff8621198ec5b0a1c3762f87e05f14\n",
      "Successfully built mpld3\n",
      "Installing collected packages: mpld3\n",
      "  Attempting uninstall: mpld3\n",
      "    Found existing installation: mpld3 0.5.10\n",
      "    Uninstalling mpld3-0.5.10:\n",
      "      Successfully uninstalled mpld3-0.5.10\n",
      "Successfully installed mpld3-0.3.1.dev1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/javadba/mpld3 'C:\\Users\\HP\\AppData\\Local\\Temp\\pip-req-build-g3hoh_ep'\n",
      "  Running command git checkout -b display_fix --track origin/display_fix\n",
      "  branch 'display_fix' set up to track 'origin/display_fix'.\n",
      "  Switched to a new branch 'display_fix'\n",
      "  Running command git submodule update --init --recursive -q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colour\n",
      "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: colour\n",
      "Successfully installed colour-0.1.5\n"
     ]
    }
   ],
   "source": [
    "# import the relevant Python packages\n",
    "!pip install mpld3\n",
    "!pip install \"git+https://github.com/javadba/mpld3@display_fix\"\n",
    "!pip install colour\n",
    "\n",
    "# for basic data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# for downloading files off the internet\n",
    "import urllib.request\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "# for network graphs\n",
    "from colour import Color\n",
    "from matplotlib.collections import LineCollection\n",
    "import networkx as nx\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON files are at addresses of this form\n",
    "def flavordb_entity_url(x):\n",
    "    return \"https://cosylab.iiitd.edu.in/flavordb/entities_json?id=\"+str(x)\n",
    "\n",
    "\n",
    "# translates the JSON file at the specified web address into a dictionary\n",
    "def get_flavordb_entity(x):\n",
    "    # source: https://stackoverflow.com/questions/12965203/how-to-get-json-from-webpage-into-python-script\n",
    "    with urllib.request.urlopen(flavordb_entity_url(x)) as url:\n",
    "        return json.loads(url.read().decode())\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the names of the \"columns\" in the raw JSON objects\n",
    "def flavordb_entity_cols():\n",
    "    return [\n",
    "        'entity_id', 'entity_alias_readable', 'entity_alias_synonyms',\n",
    "        'natural_source_name', 'category_readable', 'molecules'\n",
    "    ]\n",
    "\n",
    "\n",
    "# what we want to rename the JSON object \"columns\" to\n",
    "def flavordb_df_cols():\n",
    "    return [\n",
    "        'entity id', 'alias', 'synonyms',\n",
    "        'scientific name', 'category', 'molecules'\n",
    "    ]\n",
    "\n",
    "\n",
    "# \"subcolumns\" in the \"molecules\" column that we are interested in\n",
    "def molecules_df_cols():\n",
    "    return ['pubchem id', 'common name', 'flavor profile']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_flavordb_dataframes(flavor_df, molecules_df):\n",
    "    \"\"\"\n",
    "    Helps ensure consistent intra-column typing and converts all strings to lowercase.\n",
    "    \"\"\"\n",
    "    strtype = type('')\n",
    "    settype = type(set())\n",
    "    \n",
    "    # ensuring that these columns have type str\n",
    "    for k in ['alias', 'scientific name', 'category']:\n",
    "        flavor_df[k] = [\n",
    "            elem.strip().lower() if isinstance(elem, strtype) else ''\n",
    "            for elem in flavor_df[k]\n",
    "        ]\n",
    "    \n",
    "    # ensuring that these columns are always a set of str\n",
    "    def map_to_synonyms_set(elem):\n",
    "        if isinstance(elem, settype):\n",
    "            return elem\n",
    "        elif isinstance(elem, strtype):\n",
    "            # if it's a string of a set,\n",
    "            if elem[0] == '{' and elem[-1] == '}':\n",
    "                # convert it to a set\n",
    "                return eval(elem)\n",
    "            else:\n",
    "                # else it's probably directly from source\n",
    "                return set(elem.strip().lower().split(', '))\n",
    "        else:\n",
    "            return set()\n",
    "    \n",
    "    flavor_df['synonyms'] = [\n",
    "        map_to_synonyms_set(elem)\n",
    "        for elem in flavor_df['synonyms']\n",
    "    ]\n",
    "    \n",
    "    molecules_df['flavor profile'] = [\n",
    "        set([x.strip().lower() for x in elem])\n",
    "        for elem in molecules_df['flavor profile']\n",
    "    ]\n",
    "    \n",
    "    return [\n",
    "        flavor_df.groupby('entity id').first().reset_index(),\n",
    "        molecules_df.groupby('pubchem id').first().reset_index()\n",
    "    ]\n",
    "    \n",
    "# generate dataframes from some of the JSON objects\n",
    "def get_flavordb_dataframes(start, end):\n",
    "    \"\"\"\n",
    "    Download JSON data, converts it to DataFrames, and cleans them.\n",
    "    \n",
    "    Returns DataFrames for both foods and molecules, as well as missing JSON entries.\n",
    "    \"\"\"\n",
    "    # make intermediate values to make dataframes from\n",
    "    flavordb_data = []\n",
    "    molecules_dict = {}\n",
    "    missing = [] # numbers of the missing JSON files during iteration\n",
    "    \n",
    "    flavordb_cols = flavordb_entity_cols()\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        # we use a try-except here because some of the JSON pages are missing\n",
    "        try:\n",
    "            # 1: Find the JSON file. Gets the ith food entity, as a JSON dict\n",
    "            fdbe = get_flavordb_entity(i + 1)\n",
    "\n",
    "            # get only the relevant fields (columns) of the dict\n",
    "            flavordb_series = [fdbe[k] for k in flavordb_cols[:-1]]\n",
    "            flavordb_series.append( # convert the field to a set\n",
    "                set([m['pubchem_id'] for m in fdbe['molecules']])\n",
    "            )\n",
    "            flavordb_data.append(flavordb_series)\n",
    "\n",
    "            # update the molecules dataframe with the data in 'molecules' field\n",
    "            for m in fdbe['molecules']:\n",
    "                if m['pubchem_id'] not in molecules_dict:\n",
    "                    molecules_dict[m['pubchem_id']] = [\n",
    "                        m['common_name'],\n",
    "                        set(m['flavor_profile'].split('@'))\n",
    "                    ]\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404: # if the JSON file is missing\n",
    "                missing.append(i)\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    'Error while fetching JSON object from ' + flavordb_entity_url(x)\n",
    "                ) from e\n",
    "            \n",
    "    # generate the dataframes\n",
    "    flavordb_df = pd.DataFrame(\n",
    "        flavordb_data,\n",
    "        columns=flavordb_df_cols()\n",
    "    )\n",
    "    molecules_df = pd.DataFrame(\n",
    "        [\n",
    "            [k, v[0], v[1]]\n",
    "             for k, v in molecules_dict.items()\n",
    "        ],\n",
    "        columns=molecules_df_cols()\n",
    "    )\n",
    "    \n",
    "    # clean up the dataframe columns\n",
    "    flavordb_df, molecules_df = clean_flavordb_dataframes(flavordb_df, molecules_df)\n",
    "    \n",
    "    return [flavordb_df, molecules_df, missing]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updates & saves the download progress of your dataframes\n",
    "def update_flavordb_dataframes(df0, df1, ranges):\n",
    "    \"\"\"\n",
    "    Adds more data to the specified DataFrames, and saves them as CSV files.\n",
    "    \n",
    "    If successful, returns the specified DataFrames, now updated, and any missing JSON files.\n",
    "    \"\"\"\n",
    "    df0_old = df0\n",
    "    df1_old = df1\n",
    "    missing_old = []\n",
    "\n",
    "    # time how long it took to download the files\n",
    "    start = time.time()\n",
    "    \n",
    "    # for each range in ranges, save your progress.\n",
    "    # don't continue with the program unless everything succeeds!\n",
    "    try:\n",
    "        for a, b in ranges:\n",
    "            df0_new, df1_new, missing_new = get_flavordb_dataframes(a, b)\n",
    "            \n",
    "            df0_old = pd.concat([df0_old, df0_new], ignore_index=True)\n",
    "            df1_old = pd.concat([df1_old, df1_new], ignore_index=True)\n",
    "\n",
    "            missing_old.extend(missing_new)\n",
    "        \n",
    "        return df0_old, df1_old, missing_old\n",
    "    except:\n",
    "        raise # always throw the error so you know what happened\n",
    "    finally:\n",
    "        # even if you throw an error, you'll have saved them as csv files\n",
    "        df0_old.to_csv('flavordb.csv')\n",
    "        df1_old.to_csv('molecules.csv')\n",
    "\n",
    "        end = time.time()\n",
    "        mins = (end - start) / 60.0\n",
    "        print('Downloading took: '+ str(mins) + 'minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading took: 0.13380692402521768minutes\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14816\\4182920097.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# fill the DataFrames with JSON files up to id = 1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mranges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# update & save the dataframes as csv files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mupdate_flavordb_dataframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14816\\2991935233.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df0, df1, ranges)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mdf1_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'molecules.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mmins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m60.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading took: '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmins\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'minutes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# take new dataframes\n",
    "df0 = pd.DataFrame(columns=flavordb_df_cols())\n",
    "df1 = pd.DataFrame(columns=molecules_df_cols())\n",
    "\n",
    "# fill the DataFrames with JSON files up to id = 1000\n",
    "ranges = [(50 * i, 50 * (i + 1)) for i in range(20)]\n",
    "# update & save the dataframes as csv files\n",
    "update_flavordb_dataframes(df0, df1, ranges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
